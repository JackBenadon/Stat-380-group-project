
```{r}
packages <- c(
  "dplyr", 
  "readr", 
  "tidyr", 
  "purrr", 
  "broom",
  "magrittr",
  "corrplot",
  "caret",
  "rpart",
  "rpart.plot",
  "e1071",
  "torch", 
  "luz",
  "ramify"
)

# renv::install(packages)
sapply(packages, require, character.only=T)
```

```{r}
NNet <- nn_module(
  initialize = function(input_size, hidden_size, output_size) {
    self$input_size <- input_size
    self$hidden_size <- hidden_size
    self$output_size <- output_size
    
    self$f1 <- nn_linear(input_size + hidden_size, hidden_size)
    self$f2 <- nn_linear(hidden_size, output_size)
    self$activation <- nn_tanh()
  },
  
 forward = function(x) {
    hidden <- self$f1(x) %>% self$activation()
    output <- self$f2(hidden)
    list(output, hidden)
  }
)

nnet_fit <- NNet %>% 
  setup(
    loss = nn_mse_loss(),
    optimizer = optim_adam, 
    metrics = list(luz_metric_rmse())
  ) %>%
  set_hparams(input_size = 5, 
              hidden_size = 32, 
              output_size = 1) %>% 
  set_opt_hparams(lr = 0.005) %>% 
  fit(
    data = list(
      x = list(model.matrix(median_house_value ~ .-households, data = df_train)),
      y = list(df_train %>% select(median_house_value) %>% as.matrix)
    ),
    valid_data = list(
      x = list(model.matrix(median_house_value ~ .-households, data = df_test)),
      y = list(df_test %>% select(median_house_value) %>% as.matrix)
    ),
    dataloader_options = list(shuffle = TRUE, num_workers = 0),
    verbose = FALSE # Change to TRUE while tuning. But, set to FALSE before submitting
  )
```

Identify the important features:
```{r}
# assume "nnet_fit" is the trained neural network model
params <- nnet_fit %>% get_parameters()
weights_input_to_hidden <- params$f1$weight %>% as.array()

# find the index of the input feature with the highest weight for each hidden neuron
most_important_features <- apply(weights_input_to_hidden, 1, which.max)
```
